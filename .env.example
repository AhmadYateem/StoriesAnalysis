# HuggingFace Inference API token for LLaMA chat
# Get your token from: https://huggingface.co/settings/tokens
VITE_HF_TOKEN=hf_your_token_here

# Flask backend URL (use http://localhost:5000 for local development)
VITE_BACKEND_URL=http://localhost:5000
